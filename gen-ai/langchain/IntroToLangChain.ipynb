{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYDKh54kBoRI5VHmVte/g0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarang1998/ML-AI-DL/blob/main/gen-ai/langchain/IntroToLangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY0iKPZGrqc2",
        "outputId": "8fd92b2d-541f-4c3a-9fe5-4c54c7be0020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(prompt='Enter OpenAI API key:')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKmIGwRujY16",
        "outputId": "3b3090d3-3225-4ad7-d063-8e7dd2487842"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"] = getpass.getpass(prompt='Enter HuggingFace API key:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u__lxwwfrcql",
        "outputId": "a890a363-9d33-40ed-99af-d5842159fcbc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter HuggingFace API key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKPVw_JClIH2",
        "outputId": "91744539-9d6c-4573-a352-e05991ebaea5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using LangChain with Open AI\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWABZ13plSNq",
        "outputId": "d8d028ba-eeb8-4a16-ee01-d82a79802576"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-61402f2475db>:4: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature=0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1\n",
        "text=\"What would be a good company name for a company that makes colorful socks?\""
      ],
      "metadata": {
        "id": "AEiprvU6lYQm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.predict(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hngKP0s4lZBd",
        "outputId": "061af18a-a48f-4aeb-a32b-c7de91e52246"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-652b389f66d4>:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(llm.predict(text))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Feet Co.\" or \"Vibrant Soles Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFeszJOpldwp",
        "outputId": "a9149f64-d9ac-4e29-c5f1-6dfd064a8c6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-605043303f29>:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(llm(text))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Spectrum Socks Co.\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi5xB_nflhPk",
        "outputId": "ed0779d1-396e-4a15-b704-9adb75e396b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Socks Co.\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2\n",
        "text2 = \"I want to open a restaurant for Chinese food. Suggest a fency name for this.\""
      ],
      "metadata": {
        "id": "5vXRQaB7llVQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = llm.predict(text2)\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UNvF7X4l1Qc",
        "outputId": "a0fe0568-21e6-462f-cbc2-9d3b9e5d98c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"The Jade Dragon Restaurant\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using LangChain with Hugging Face\n",
        "\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKS2-F8LmvOU",
        "outputId": "e6f3e0c6-8613-4aea-d8d5-8407ce36c661"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n"
      ],
      "metadata": {
        "id": "EFr7DGotm3PF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the client with the model repo ID\n",
        "client = InferenceClient(model=\"google/flan-t5-large\")\n",
        "\n",
        "# Make a text generation request\n",
        "prompt1 = \"I want to open a restaurant for Indian food. Suggest a fancy name for this.\"\n",
        "response = client.text_generation(prompt1, max_new_tokens=64, temperature= 0)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B2am7CUq2ON",
        "outputId": "4f850858-2fb6-4497-9afb-cb789666b3d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indian restaurant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = \"translate English to German: How old are you?\"\n",
        "response = client.text_generation(prompt2, max_new_tokens=64, temperature= 0)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z2XEZ8om6nJ",
        "outputId": "4fb75381-ab37-40e1-c8da-f8a37ab58718"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wie alte sind Sie?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Prompt templates\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "p = prompt_template_name.format(cuisine=\"indian\")\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JENn-EzHsNrx",
        "outputId": "38e54329-40c8-481f-b3cf-47fa7f84dd03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for indian food. Suggest a fancy name for this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sDi37VvNsXmy",
        "outputId": "fa97aaa1-3e1e-4e9c-ebe1-a36d395cf665"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chains : Combine LLMs and Prompts in multi-step workflows\n",
        "\n",
        "## LLM Chain\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "response= chain.invoke(\"colorful socks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzp0CaPDstW-",
        "outputId": "ce9b9c9b-aa0b-4eb6-f3cf-d07c431cca8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'product': 'colorful socks', 'text': '\\n\\nRainbow Socks Co. or ChromaSock Co.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "response=chain.invoke(\"Mexican\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my4x1G7wtT72",
        "outputId": "c23772fe-637d-46b0-bc97-3a7a4e77809b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'Mexican', 'text': '\\n\\n\"El Sabor de México\" (The Flavor of Mexico)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
        "response=chain.invoke(\"Mexican\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBX3Tq8stgYy",
        "outputId": "fad49904-44d3-4332-b17e-d584ae6ab63f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'Mexican', 'text': '\\n\\n\"El Sabor Exquisito\"'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Sequential Chain\n",
        "\n",
        "llm = OpenAI(temperature=0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
        ")\n",
        "\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
      ],
      "metadata": {
        "id": "zMjQoIcMuVs0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
        "\n",
        "content = chain.run(\"indian\")\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1EN6e31ucbh",
        "outputId": "0c504a2a-340d-4cac-c8d6-83b9b1d09158"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Spicy Chicken Tikka Masala\n",
            "2. Lamb Vindaloo\n",
            "3. Vegetable Samosas\n",
            "4. Tandoori Shrimp\n",
            "5. Palak Paneer (spinach and cottage cheese curry)\n",
            "6. Aloo Gobi (potatoes and cauliflower curry)\n",
            "7. Chana Masala (chickpea curry)\n",
            "8. Butter Chicken\n",
            "9. Biryani (spiced rice dish with choice of protein)\n",
            "10. Naan bread\n",
            "11. Mango Lassi (yogurt-based drink)\n",
            "12. Tandoori Chicken skewers\n",
            "13. Saag Aloo (spinach and potato curry)\n",
            "14. Malai Kofta (vegetable dumplings in a creamy sauce)\n",
            "15. Chicken or Vegetable Korma (mild and creamy curry)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential Chain\n",
        "\n",
        "from langchain.chains import SequentialChain\n",
        "\n",
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")\n",
        "\n",
        "print(chain({\"cuisine\": \"indian\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a8BRZMVumEm",
        "outputId": "76de5494-0402-474d-8390-164edfeaee5e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-96ff033a781c>:27: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(chain({\"cuisine\": \"indian\"}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'indian', 'restaurant_name': '\\n\\n\"Spice Oasis\"', 'menu_items': '\\n\\n1. Spicy Chicken Tikka Masala\\n2. Vegetable Samosas\\n3. Lamb Vindaloo\\n4. Tandoori Shrimp\\n5. Aloo Gobi (spiced cauliflower and potatoes)\\n6. Chana Masala (spicy chickpea curry)\\n7. Chicken Korma\\n8. Palak Paneer (spinach and cheese curry)\\n9. Dum Biryani (spicy rice dish with choice of protein)\\n10. Naan bread with garlic and chili flakes\\n11. Mango Lassi (spiced yogurt drink)\\n12. Beef Madras\\n13. Vegetable Biryani\\n14. Tandoori Tofu Tikka\\n15. Spicy Vada Pav (Indian spiced potato burger)\\n16. Coconut Curry Shrimp\\n17. Saag Chicken (spicy chicken and spinach curry)\\n18. Spicy Mango Chutney\\n19. Malai Kofta (spicy vegetable dumplings in creamy sauce)\\n20. Gulab Jamun (spicy sweet Indian dessert).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agents and Tools\n",
        "\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rinOFiwvbay",
        "outputId": "42eb1550-4fbd-4a77-f019-162ec81b6e74"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=4457745a2700a305808e23d04f174a08f676c0f6cfeab92a028242a0341134ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "g7L-TDNbvdeI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "Xq95Tzssvfgi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\",], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "agent.run(\"What was the GDP of US in 2024?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "sChqkSC7vhXG",
        "outputId": "89e7c116-3760-4daa-fd6e-5ad14e5f639f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should always think about what to do\n",
            "Action: wikipedia\n",
            "Action Input: GDP of US in 2024\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of U.S. states and territories by GDP\n",
            "Summary: This is a list of U.S. states and territories by gross domestic product (GDP). This article presents the 50 U.S. states and the District of Columbia and their nominal GDP at current prices.\n",
            "The data source for the list is the Bureau of Economic Analysis (BEA) in 2024. The BEA defined GDP by state as \"the sum of value added from all industries in the state.\"\n",
            "Nominal GDP does not take into account differences in the cost of living in different countries, and the results can vary greatly from one year to another based on fluctuations in the exchange rates of the country's currency. Such fluctuations may change a country's ranking from one year to the next, even though they often make little or no difference in the standard of living of its population.\n",
            "Overall, in the calendar year 2024, the United States' Nominal GDP at Current Prices totaled at $29.017 trillion, as compared to $25.744 trillion in 2022.\n",
            "The three U.S. states with the highest GDPs were California ($4.080 trillion), Texas ($2.695 trillion), and New York ($2.284 trillion). The three U.S. states with the lowest GDPs were Vermont ($45.4 billion), Wyoming ($53.0 billion), and Alaska ($69.8 billion).\n",
            "GDP per capita also varied widely throughout the United States in 2024, with New York ($117,332), Massachusetts ($110,561), and Washington (state) ($108,468) recording the three highest GDP per capita figures in the U.S., while Mississippi ($53,061), Arkansas ($60,276), and West Virginia ($60,783) recorded the three lowest GDP per capita figures in the U.S. The District of Columbia, though, recorded a GDP per capita figure far higher than any U.S. state in 2024 at $263,220.\n",
            "\n",
            "Page: List of countries by GDP (nominal) per capita\n",
            "Summary: This is a list of countries by nominal GDP per capita.\n",
            "GDP per capita is often considered an indicator of a country's standard of living; however, this is inaccurate because GDP per capita is not a measure of personal income. Measures of personal income include average wage, real income, median income, disposable income and GNI per capita.\n",
            "Comparisons of GDP per capita are also frequently made on the basis of purchasing power parity (PPP), to adjust for differences in the cost of living in different countries, see List of countries by GDP (PPP) per capita. PPP largely removes the exchange rate problem but not others; it does not reflect the value of economic output in international trade, and it also requires more estimation than GDP per capita. On the whole, PPP per capita figures are more narrowly spread than nominal GDP per capita figures.\n",
            "The figures presented here do not take into account differences in the cost of living in different countries, and the results vary greatly from one year to another based on fluctuations in the exchange rates of the country's currency. Such fluctuations change a country's ranking from one year to the next, even though they often make little or no difference to the standard of living of its population.\n",
            "For change of GDP per capita over time as a measure of economic growth, see real GDP growth and real GDP per capita growth.\n",
            "Non-sovereign entities (the world, continents, and some dependent territories) and states with limited international recognition are included in the list in cases in which they appear in the sources. These economies are not ranked in the charts here (except Kosovo and Taiwan), but are listed in sequence by GDP for comparison. In addition, non-sovereign entities are marked in italics. Four UN members (Cuba, Liechtenstein, Monaco and North Korea) do not belong to the International Monetary Fund (IMF), hence their economies are not ranked below. Kosovo, despite not being a member of the United Nations, is a member of IMF. Taiwan is not a IMF member but it is still listed in the official IMF indices.\n",
            "Several leading GDP-per-capita (nominal) jurisdictions may be considered tax havens, and their GDP data subject to material distortion b\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The GDP of the US in 2024 was $29.017 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The GDP of the US in 2024 was $29.017 trillion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXqSnJ6w5p7",
        "outputId": "bc6f3d85-ff59-47da-ea16-424d99226aea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Casa Delicioso\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OqPasJ0xCor",
        "outputId": "dc61224c-e781-46b4-c88a-0f4b754e4f09"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Fusion Spice House\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pKX4UN_xKpo",
        "outputId": "1d58d23e-1c16-4ebe-b18f-47403f44ad31"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversation Buffer Memory\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pEs8C6txP-v",
        "outputId": "bb234ab9-d43e-4a1e-839d-291d03a8857e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-c6cf17605daf>:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"La Cantina del Sol\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Arabic\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWEdoiTJxWp9",
        "outputId": "1bf3c1e9-3c1e-4538-f2b1-71280e87fdb8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Sahara Palace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LNGmT8hxZH3",
        "outputId": "29463f1d-af84-4cbb-cb66-263d8c53f5b2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\n",
            "\"La Cantina del Sol\"\n",
            "Human: Arabic\n",
            "AI: \n",
            "\n",
            "\"Sahara Palace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversation Chain\n",
        "\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7CehN4wxeKS",
        "outputId": "ce430d44-7b07-46e8-9d0b-f326667aa533"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-e9279c385800>:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  convo = ConversationChain(llm=OpenAI(temperature=0.7))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Se_icTUKxq-6",
        "outputId": "1a861cc5-ee76-4fc3-8917-e7ce6615e85f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was won by the West Indies team in 1975. It was held in England and consisted of eight teams, with India being the runner-up. The West Indies team was led by Clive Lloyd and had players like Viv Richards and Andy Roberts. They defeated Australia in the final by 17 runs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_s6yPPVkxtWV",
        "outputId": "88ce9e65-6971-4571-ae59-6cabcaeeb667"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EgTVD-ipxxKJ",
        "outputId": "b0f99e4e-9b83-42f8-b8a6-8834cbfd9cd2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning team, the West Indies, was Clive Lloyd. He was a left-handed batsman and a medium-paced bowler. He was known for his strong leadership skills and led the West Indies team to two consecutive World Cup victories in 1975 and 1979. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_fg1LWlx1P1",
        "outputId": "a8c0f973-706d-4696-e6de-0ebc725a6717"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by the West Indies team in 1975. It was held in England and consisted of eight teams, with India being the runner-up. The West Indies team was led by Clive Lloyd and had players like Viv Richards and Andy Roberts. They defeated Australia in the final by 17 runs.\n",
            "Human: How much is 5+5?\n",
            "AI:   5+5 is equal to 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team, the West Indies, was Clive Lloyd. He was a left-handed batsman and a medium-paced bowler. He was known for his strong leadership skills and led the West Indies team to two consecutive World Cup victories in 1975 and 1979. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversation Buffer Window Memory\n",
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=3)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "3JT9Qdq7x4ZS",
        "outputId": "63fd46ed-32f8-40df-bc1e-e37ed2efe889"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-f16f53a72db3>:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(k=3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The first cricket world cup was won by the West Indies in 1975. The final match was played between the West Indies and Australia at Lord's Cricket Ground in London. The West Indies won by 17 runs. The captain of the West Indies team was Clive Lloyd and the man of the match was Viv Richards. This was a historic moment for the West Indies as it was the first time they had won the cricket world cup.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dgg8qUUEx_Em",
        "outputId": "79aa6c47-04cc-418b-b7ee-b07120418c6d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "bOr4bhWjyDR0",
        "outputId": "f7dce9a9-c94a-4efa-eb5f-214d6880c191"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning team was Clive Lloyd. He was a legendary cricketer from the West Indies and led his team to victory in the first cricket world cup in 1975. He was also the captain of the West Indies team when they won the second cricket world cup in 1979. He is considered one of the greatest captains in the history of cricket.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSiAHL_SyEnb",
        "outputId": "b8a65772-4b40-4963-8dac-6276d63a3b3c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by the West Indies in 1975. The final match was played between the West Indies and Australia at Lord's Cricket Ground in London. The West Indies won by 17 runs. The captain of the West Indies team was Clive Lloyd and the man of the match was Viv Richards. This was a historic moment for the West Indies as it was the first time they had won the cricket world cup.\n",
            "Human: How much is 5+5?\n",
            "AI:   5+5 is equal to 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd. He was a legendary cricketer from the West Indies and led his team to victory in the first cricket world cup in 1975. He was also the captain of the West Indies team when they won the second cricket world cup in 1979. He is considered one of the greatest captains in the history of cricket.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5CGZ3W66yGQO",
        "outputId": "d1d49ee7-cb8b-48e6-e92c-0c39eb6833a8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning team was Clive Lloyd.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AdHZQ_lyNnc",
        "outputId": "01b28140-00b1-41b0-b7c7-3a55fb36a2e5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: How much is 5+5?\n",
            "AI:   5+5 is equal to 10.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd. He was a legendary cricketer from the West Indies and led his team to victory in the first cricket world cup in 1975. He was also the captain of the West Indies team when they won the second cricket world cup in 1979. He is considered one of the greatest captains in the history of cricket.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team was Clive Lloyd.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading PDF documents\n",
        "\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcqvGTjuDmAB",
        "outputId": "c1246db1-9328-4430-ef4e-df9ef0e9f75e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/300.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/300.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"./content/TarangResume.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "5nZXGgn7DtgL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6McpW1G6EoLE",
        "outputId": "0940d746-831c-4fb3-86ef-9c6c6879dd75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Skia/PDF m134 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Resume - Tarang Nair', 'source': './content/TarangResume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='TARANG  NAIR  Arlington,  Virginia  |  571-385-5625  |  tarang98@umd.edu |  linkedin.com/in/tarangnair1998 |  github.com/tarang1998 |  tarangnair.com  \\nEDUCATION  University  Of  Maryland,  College  Park                    Maryland,  United  States  Masters  Of  Engineering  in  Software  Engineering                                      Expected  2025  \\nVidyalankar\\n \\nInstitute\\n \\nOf\\n \\nTechnology,\\n \\nMumbai\\n \\nUniversity\\n \\n                    \\n \\n \\n \\n                                        \\nMumbai,\\n \\nIndia\\n Bachelors  Of  Engineering  in  Computer  Engineering                                                    July  2016  -  July  2020   \\nWORK  EXPERIENCE  FINRA                            Rockville,  MD,  USA  (Hybrid)     \\nSystem\\n \\nAnalyst\\n \\nIntern\\n \\n \\n \\n \\n \\n \\n                   \\n \\n                        \\n \\n \\n \\n \\nMay\\n \\n2024\\n \\n-\\n \\nAug\\n \\n2024\\n ●  Facilitated  seamless  integration  of  ServiceNow  and  AWS  services  with  internal  applications,  reducing  team  effort  by  15  hours/week.  ●  Automated  backend  processes  using  Python ,  JavaScript ,  and  Bash  scripts,  enhancing  efficiency  and  reducing  data  inconsistencies  by  10%.  ●  Collaborated  with  business  units  to  configure  SaaS  solutions,  streamlining  processes  and  defining  integration  requirements.  Xero  Apps                                               Mumbai,  India  (Remote)     \\nSoftware\\n \\nDevelopment\\n \\nEngineer\\n   \\n \\n \\n \\n \\n \\n \\n \\n \\n                    \\nDecember\\n \\n2022\\n \\n-\\n \\nJuly\\n \\n2023\\n ●  Architected  products  using  Flutter  and  GCP ,  managing  a  FMCG  database  with  2  million+  products,  serving  over  10,000+  stores  globally.  ●  Engineered  a  system  using  GCP  services,  to  help  provide  retail  shops  in  India  with  an  online  presence,  thereby  increasing  sales  by  10%.  ●  Optimized  subscription  and  payment  backend  API  processes,  improving  financial  tracking  accuracy  and  reducing  error  margins  by  15%.  ●  Implemented  100+  APIs  in  Python  and  TypeScript  using  Clean  Architecture  Principles  leveraging  GCP’s  serverless  Cloud  functions .  Cerebranium                                                Berlin,  Germany  (Remote)      Software  Development  Engineer  -  2                                    July  2020  -  July  2022  ●  Managed  a  5  member  team  to  build  ed-tech  products  using  Flutter,  GCP  and  Unity3D ,  serving  over  500+  schools  and  5,000+  learners.  ●  Spearheaded  database  migration  from  a  NoSQL  ( Firebase )  to  a  SQL  database  ( Google  Spanner ),  resulting  in  a  20%  faster  query  output.  ●  Served  as  Scrum  Master,  leading  Agile  Scrum  practices,  ensuring  90%  adherence  to  deadlines,  achieving  sprint  goals  in  95%  of  the  sprints.  ●  Utilized  Big  Query  and  Google  Looker  Studio ,  for  data  analysis  and  visualization,  providing  insights  and  reducing  cost  by  10%.  ●  Configured  automated  CI/CD  pipelines  for  APIs  and  mobile  app  daily  builds  to  receive  early  feedback  using  Github  Actions.  ●  Set  up  monitoring  of  error  occurrences  of  the  applications  in  Sentry ,  increasing  the  application  stability  to  85%.  ●  Collaborated  with  the  team  to  develop  a  Computer  vision  proctoring  system,  capable  of  processing  8000  assessment  videos  per  day.  Godrej  InfoTech  Limited                           Mumbai,  India     \\nJava\\n \\nSoftware\\n \\nDeveloper\\n \\nIntern\\n \\n \\n \\n \\n \\n \\n \\n \\n           \\n \\n         \\n \\n              \\nJune\\n \\n2019\\n \\n-\\n \\nJuly\\n \\n2019\\n ●  Created  web  applications  using  the  Spring  Framework ,  achieving  50%  unit  test  coverage  and  improving  the  overall  stability  of  the  app.   \\nPROJECT  EXPERIENCE  EKS  and  Monitoring  with  Open-Telemetry  (https://github.com/tarang1998/EKS-and-Monitoring-with-OpenTelemetry )     Dec  2024  -  Present  ●  Architected  and  deployed  a  monitoring  solution  for  Kubernetes  applications  using  AWS  EKS,  Docker,  OpenTelemetry,  Helm,  and  Grafana.  ●  Automated  CI/CD  pipelines,  testing,  to  optimize  system  reliability  and  performance  monitoring.  AWS  Cloud  Computing  (github.com/tarang1998/AWS-Cloud-Computing |  Architecture)           Oct  2024  -  Present  ●  Designed  a  scalable,  secure  PHP,  MySQL  E-commerce  application  using  AWS  cloud  services,  including  key  features  like  AutoScaling,  WAF  \\nand\\n \\nCloudWatch,\\n \\nenabling\\n \\nthe\\n \\nsystem\\n \\nto\\n \\nhandle\\n \\na\\n \\n100%\\n \\nincrease\\n \\nin\\n \\ntraffic\\n \\nwith\\n \\nzero\\n \\ndowntime.\\n Application  Deployment  with  Docker  and  Kubernetes  (https://github.com/tarang1998/docker-k8s |  Architecture)                 Oct  2024  -  Present  ●  Containerized  and  deployed  a  web  application  using  Docker  and  Kubernetes  on  AWS  EKS,  achieving  high  availability  and  enabling  \\nseamless\\n \\nscaling\\n \\nto\\n \\nhandle\\n \\n200%\\n \\nmore\\n \\ntraffic\\n \\nduring\\n \\npeak\\n \\ndemand.\\n KiranaFast  (Android |  iOS |  kiranafast.com)  |  EaseMyStore  (Android |  iOS),  Xero  Apps                                     Dec  2022  -  July  2022   ●  Devised  an  inventory  and  billing  management  application  offering  a  subscription-based  service  to  retail  stores,  streamlining  operations  and  \\nimproving\\n \\ninventory\\n \\ntracking\\n \\nefficiency.\\n ●  Engineered  comprehensive  code  flows  and  sophisticated  data  models  for  inventory,  billing,  batch,  and  sub-organization  management,  to  meet  \\nuser\\n \\nrequirements\\n \\nand\\n \\nreduce\\n \\noperational\\n \\noverhead\\n \\nwithin\\n \\n6\\n \\nmonths.\\n Myracle.io  (Android |  iOS |  Myracle.io) ,  Cerebranium             Dec  2021  -  July  2022  ●  Partnered  with  subject  matter  experts  and  students  to  develop  an  XR  application  featuring  interactive  3D  science  experiments,  increasing  \\nstudent\\n \\nengagement\\n \\nand\\n \\nimproving\\n \\ncomprehension\\n \\nof\\n \\ncomplex\\n \\nconcepts.\\n ●  Established  the  base  architecture  using  a  publisher-subscriber  design  pattern,  enabling  efficient  and  scalable  development  of  game  scenes  and  \\nreducing\\n \\ndevelopment\\n \\ntime.\\n Promexa  (Android |  iOS)  |  Promexa  Institution  (Android |  iOS),  Cerebranium                                   July  2020  -  Dec  2021  ●  Developed  an  exam  conduction  mobile  application  with  AI-powered  supervision,  enabling  offline  exam  capabilities  and  ensuring  an  increase  \\nin\\n \\nexam\\n \\nsecurity\\n \\nand\\n \\naccessibility.\\n ●  Strategized  a  process  to  capture  and  compress  the  examination  videos  in  offline  mode,  enabling  seamless  upload  and  AI  pipeline  integration  \\nfor\\n \\nprocessing\\n \\nonce\\n \\nconnectivity\\n \\nis\\n \\nrestored,\\n \\nimproving\\n \\nexam\\n \\nsupervision\\n \\nefficiency.\\n  \\nSKILLS  AND  INTEREST  \\nProgramming\\n \\nLanguages\\n:\\n \\nPython,\\n \\nC,\\n \\nC++,\\n \\nC#,\\n \\nJava,\\n \\nSQL,\\n \\nTypeScript,\\n \\nJavascript.\\n \\n|\\n \\nWeb/Mobile\\n \\nDevelopment\\n:\\n \\nHTML,\\n \\nCSS,\\n \\nBootstrap,\\n \\nJavaScript,\\n \\nReactJS,\\n \\nFlutter,\\n \\nAndroid,\\n \\nNodeJS.\\n \\n|\\n \\nCloud/DevOps\\n:\\n \\nGCP,\\n \\nAWS,\\n \\nDocker,\\n \\nKubernetes,\\n \\nJenkins,\\n \\nGithub.\\n \\n|\\n \\nTools\\n \\n&\\n \\nFrameworks\\n:\\n \\nGit,\\n \\nServiceNow,\\n \\nJIRA,\\n \\nJenkins\\n \\n|\\n \\nInterest\\n:\\n \\nSystem\\n \\nDesign,\\n \\nAI/ML,\\n \\nDevOps.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}